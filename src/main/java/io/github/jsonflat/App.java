package io.github.jsonflat;

import com.fasterxml.jackson.databind.JsonNode;
import com.fasterxml.jackson.databind.node.ObjectNode;
import io.github.jsonflat.schema.AutoSchemaFactory;
import io.github.jsonflat.schema.JsonSchemaFactory;
import io.github.jsonflat.schema.Schema;
import io.github.jsonflat.utils.JsonUtils;
import io.github.jsonflat.utils.StringUtils;
import com.jayway.jsonpath.JsonPath;
import lombok.Data;
import lombok.Getter;

import java.io.BufferedReader;
import java.io.IOException;
import java.io.InputStreamReader;
import java.io.PrintStream;
import java.nio.file.Files;
import java.nio.file.Paths;
import java.util.*;
import java.util.stream.Stream;

/**
 * 
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not
 * use this file except in compliance with the License. You may obtain a copy of
 * the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 *
 * @author Evgeniy Chukanov
 */
public class App {
	private static final String CSV_DELIMITER = ";";

	public static void main(String[] args) {
		try {
			final Stream<String> lines;
			final PrintStream out;
			final Config config = Config.build(args);
			if (config.isHelp()) {
				System.out.println("Utility for flatting JSON documents from the command line.\n" +
						"Supports receiving and outputting data via standard input/output streams.\n" +
						"Supports log files on input. Every line will cut till first '[' or '{'.\n" +
						"\n" +
						"Arguments:\n" +
						"-i\tPath to the input file. By default standard input.\n" +
						"-o\tPath to the output file. By default standard output.\n" +
						"-f\tIf \"-s\" parameter is not set, defines JSONPath for filter JSON documents to processing. By default no filtering.\n" +
						"-s\tPath to parsing scheme file. By default scheme will be autogenerated by input JSON documents.\n" +
						"-d\tCustom delimiter for result columns naming. By default \"_\"\n" +
						"-e\tInput file encoding. By default \"utf8\"\n" +
						"-n\tIf \"-s\" parameter is not set, generate scheme only by first line.\n" +
						"-a\tExplode primitive arrays to rows. By default keeps arrays as is\n" +
						"-c\tExplode arrays of objects to columns. By default explode to rows\n" +
						"-csv\tWrite result in csv format. Delimiter ';'. Works fine only with -s or -n parameter. By default write in json\n" +
						"-h\tPrint this help\n" +
						"\n" +
						"Any other parameters define result JSON column set.");
				return;
			}
			if (config.getInputPath() != null) {
				lines = Files.lines(Paths.get(config.getInputPath()));
			} else {
				lines = new BufferedReader(new InputStreamReader(System.in, config.encoding)).lines();
			}
			if (config.getOutputPath() != null) {
				out = new PrintStream(config.getOutputPath());
			} else {
				out = System.out;
			}
			SchemaHolder holder = new SchemaHolder();
			lines
				.map(StringUtils::preprocessLog)
				.forEachOrdered(line -> {
				try {
					ObjectNode json = (ObjectNode) Transformer.MAPPER.readTree(line);
					if (holder.transformer == null) {
						Schema schema;
						if (config.getSchemePath() != null) {
							String schemaString = new String(Files.readAllBytes(Paths.get(config.getSchemePath())));
							schema = JsonSchemaFactory.builder().build().generate(schemaString);
						} else {
							schema = AutoSchemaFactory.builder()
									.columnStringFilters(config.getColumns())
									.filterRowsPath(config.getJsonFilter())
									.delimiter(config.delimiter)
									.primitiveArraysGroup(
											config.explodeSimpleArrays ?
													Schema.GroupPolicy.NO_GROUP :
													config.csv ?
															Schema.GroupPolicy.CONCAT :
															Schema.GroupPolicy.ARRAY
									)
									.complexArraysGroup(
											config.explodeComplexArraysToColumns ?
													Schema.GroupPolicy.COLUMNS : Schema.GroupPolicy.NO_GROUP
									)
									.build()
									.generate(json);
						}
						if (config.csv) {
							holder.columnNames = schema.getResultNames();
							out.println(JsonUtils.writeCsvHeader(holder.columnNames, CSV_DELIMITER));
						}
						holder.transformer = new Transformer(schema);
					} else if (config.getSchemePath() == null && !config.schemaByFirstLine) {
						Schema newSchema = AutoSchemaFactory.builder()
								.columnStringFilters(config.getColumns())
								.filterRowsPath(config.getJsonFilter())
								.delimiter(config.delimiter)
								.primitiveArraysGroup(
										config.explodeSimpleArrays ?
												Schema.GroupPolicy.NO_GROUP :
												config.csv ?
														Schema.GroupPolicy.CONCAT :
														Schema.GroupPolicy.ARRAY
								)
								.complexArraysGroup(
										config.explodeComplexArraysToColumns ?
												Schema.GroupPolicy.COLUMNS : Schema.GroupPolicy.NO_GROUP
								)
								.build()
								.generate(json);
						holder.transformer.getSchema().merge(newSchema);
					}
					if (config.csv) {
						for (JsonNode node : holder.transformer.transform(json))
							out.println(JsonUtils.writeCsvValue(holder.columnNames, node, CSV_DELIMITER));
					} else {
						for (JsonNode node : holder.transformer.transform(json))
							out.println(node.toString());
					}
				} catch (IOException e) {
					//skip, do nothing
				}
			});
		} catch (Exception e) {
			System.err.println("Error: " + e.getLocalizedMessage());
			e.printStackTrace();
		}
	}


	@Getter
	static class Config {
		String inputPath;
		String outputPath;
		List<String> columns = Collections.emptyList();
		String jsonFilter;
		String schemePath;
		String delimiter = Schema.DEFAULT_DELIMITER;
		String encoding = "utf8";
		boolean schemaByFirstLine = false;
		boolean help;
		boolean csv;
		boolean explodeSimpleArrays;
		boolean explodeComplexArraysToColumns = false;


		private static Config build(String[] args) throws Exception {
			Config config = new Config();
			List<String> params = new ArrayList<>(Arrays.asList(args));
			config.help = params.remove("-h");
			popParameter("-i", params).ifPresent(
				v-> {
					config.inputPath = v;
					if (!Files.isReadable(Paths.get(v))) {
						throw new RuntimeException("can't read input file " + v);
					}
				}
		  );
			popParameter("-o", params).ifPresent(v -> config.outputPath = v);
			popParameter("-f", params).ifPresent(
				v -> {
					config.jsonFilter = v;
					JsonPath.compile(config.jsonFilter, p -> true); //check on error
				}
			);
			popParameter("-s", params).ifPresent(
				v -> {
					config.schemePath = v;
					if (!Files.isReadable(Paths.get(v)))
						throw new RuntimeException("can't read scheme file" + v);
				}
			);
			popParameter("-d", params).ifPresent(v -> config.delimiter = v);
			popParameter("-e", params).ifPresent(v -> config.encoding = v);
			config.schemaByFirstLine = params.remove("-n");
			config.csv = params.remove("-csv");
			config.explodeSimpleArrays = params.remove("-a");
			config.explodeComplexArraysToColumns = params.remove("-c");
			config.columns = params;
			return config;
		}

		private static Optional<String> popParameter(String param, List<String> params) throws Exception {
			int idx = params.indexOf(param);
			if (idx >= 0) {
				if (params.size() > idx + 1) {
					params.remove(idx); //remove param name
					String value = params.get(idx);
					params.remove(idx); //remove param value
					if (StringUtils.isNotBlank(value)) {
						return Optional.of(value);
					}
				} else {
					throw new Exception("check '" + param + "' parameter value");
				}
			}
			return Optional.empty();
		}
	}

	@Data
	private static class SchemaHolder {
		Transformer transformer;
		List<String> columnNames;
	}
}
